__version__ = (1, 4, 8 , 8)

# meta developer: @sunshinelzt

# ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
# ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù
# ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  
# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ïö‚ïê‚ïê‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  
# ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

import google.generativeai as genai
import os
import time
import io
import json
import asyncio
import random
import base64
import hashlib
from typing import Tuple, Optional, Dict, Any, List, Union, Callable
import logging
from contextlib import suppress
from functools import wraps
from PIL import Image
from .. import loader, utils
import aiohttp


logger = logging.getLogger(__name__)


def retry_decorator(max_retries=3, delay_base=2):
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    logger.error(f"Error in {func.__name__} (attempt {attempt+1}/{max_retries}): {str(e)}")
                    if attempt == max_retries - 1:
                        raise
                    wait_time = delay_base ** attempt
                    await asyncio.sleep(wait_time)
        return wrapper
    return decorator


class AIModel:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –º–æ–¥–µ–ª–µ–π –ò–ò"""
    def __init__(self, api_key: str, proxy: Optional[str] = None, timeout: int = 60):
        self.api_key = api_key
        self.proxy = proxy
        self.timeout = timeout

    async def generate_text(self, prompt: str, system_prompt: Optional[str] = None, **kwargs) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞"""
        raise NotImplementedError("Subclasses must implement this method")

    async def generate_with_image(self, prompt: str, image_data: bytes, mime_type: str, system_prompt: Optional[str] = None) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∑–∞–ø—Ä–æ—Å–∞"""
        raise NotImplementedError("Subclasses must implement this method")

    async def get_connector_and_timeout(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ —Ç–∞–π–º–∞—É—Ç –¥–ª—è HTTP-–∑–∞–ø—Ä–æ—Å–æ–≤"""
        conn = aiohttp.TCPConnector(ssl=False)
        timeout = aiohttp.ClientTimeout(total=self.timeout)
        return conn, timeout


class GeminiModel(AIModel):
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏ Gemini –æ—Ç Google"""
    def __init__(self, api_key: str, model_name: str = "gemini-1.5-flash", system_instruction: str = "", proxy: Optional[str] = None, timeout: int = 60):
        super().__init__(api_key, proxy, timeout)
        self.model_name = model_name
        self.system_instruction = system_instruction
        if proxy:
            os.environ["HTTP_PROXY"] = proxy
            os.environ["HTTPS_PROXY"] = proxy

    @retry_decorator()
    async def generate_text(self, prompt: str, system_prompt: Optional[str] = None, **kwargs) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é Gemini"""
        genai.configure(api_key=self.api_key)
        model = genai.GenerativeModel(
            model_name=self.model_name,
            system_instruction=system_prompt or self.system_instruction or None,
        )
        
        content_parts = [genai.protos.Part(text=prompt)]
        response = model.generate_content(content_parts)
        return response.text.strip() if response.text else "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini."

    @retry_decorator()
    async def generate_with_image(self, prompt: str, image_data: bytes, mime_type: str, system_prompt: Optional[str] = None) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∑–∞–ø—Ä–æ—Å–∞"""
        genai.configure(api_key=self.api_key)
        model = genai.GenerativeModel(
            model_name=self.model_name,
            system_instruction=system_prompt or self.system_instruction or None,
        )
        
        content_parts = [
            genai.protos.Part(text=prompt),
            genai.protos.Part(
                inline_data=genai.protos.Blob(
                    mime_type=mime_type,
                    data=image_data
                )
            )
        ]
        
        response = model.generate_content(content_parts)
        return response.text.strip() if response.text else "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini."


class ChatGPTModel(AIModel):
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏ ChatGPT –æ—Ç OpenAI"""
    def __init__(self, api_key: str, model_name: str = "gpt-4o", proxy: Optional[str] = None, timeout: int = 60):
        super().__init__(api_key, proxy, timeout)
        self.model_name = model_name

    @retry_decorator()
    async def generate_text(self, prompt: str, system_prompt: Optional[str] = None, **kwargs) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é ChatGPT"""
        conn, timeout = await self.get_connector_and_timeout()
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model_name,
            "messages": []
        }
        
        if system_prompt:
            payload["messages"].append({"role": "system", "content": system_prompt})
            
        payload["messages"].append({"role": "user", "content": prompt})
        
        async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:
            async with session.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=payload,
                proxy=self.proxy
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    return data.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
                else:
                    error_text = await response.text()
                    logger.error(f"OpenAI API error: {error_text}")
                    raise Exception(f"–û—à–∏–±–∫–∞ API OpenAI: {response.status} - {error_text}")

    @retry_decorator()
    async def generate_with_image(self, prompt: str, image_data: bytes, mime_type: str, system_prompt: Optional[str] = None) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∑–∞–ø—Ä–æ—Å–∞"""
        conn, timeout = await self.get_connector_and_timeout()
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # Convert image data to base64
        base64_image = base64.b64encode(image_data).decode("utf-8")
        image_content_type = mime_type
        
        # Prepare messages for the API
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
            
        # Add user message with image
        messages.append({
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:{image_content_type};base64,{base64_image}"
                    }
                }
            ]
        })
        
        payload = {
            "model": "gpt-4o",  # Using GPT-4 with vision capabilities
            "messages": messages
        }
        
        async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:
            async with session.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=payload,
                proxy=self.proxy
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    return data.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
                else:
                    error_text = await response.text()
                    logger.error(f"OpenAI API error: {error_text}")
                    raise Exception(f"–û—à–∏–±–∫–∞ API OpenAI: {response.status} - {error_text}")


class DeepSeekModel(AIModel):
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏ DeepSeek"""
    def __init__(self, api_key: str, model_name: str = "deepseek-chat", proxy: Optional[str] = None, timeout: int = 60):
        super().__init__(api_key, proxy, timeout)
        self.model_name = model_name

    @retry_decorator()
    async def generate_text(self, prompt: str, system_prompt: Optional[str] = None, **kwargs) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é DeepSeek"""
        conn, timeout = await self.get_connector_and_timeout()
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model_name,
            "messages": []
        }
        
        if system_prompt:
            payload["messages"].append({"role": "system", "content": system_prompt})
            
        payload["messages"].append({"role": "user", "content": prompt})
        
        async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:
            async with session.post(
                "https://api.deepseek.com/v1/chat/completions",
                headers=headers,
                json=payload,
                proxy=self.proxy
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    return data.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
                else:
                    error_text = await response.text()
                    logger.error(f"DeepSeek API error: {error_text}")
                    raise Exception(f"–û—à–∏–±–∫–∞ API DeepSeek: {response.status} - {error_text}")

    async def generate_with_image(self, prompt: str, image_data: bytes, mime_type: str, system_prompt: Optional[str] = None) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∑–∞–ø—Ä–æ—Å–∞ - –¥–ª—è DeepSeek –±–∞–∑–æ–≤–∞—è –≤–µ—Ä—Å–∏—è –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å"""
        raise NotImplementedError("DeepSeek –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –≤–≤–æ–¥ –≤ –±–∞–∑–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ API")


class ImageGenerator:
    """–ö–ª–∞—Å—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏"""
    def __init__(self, api_key: str, model_name: str = "flux", proxy: Optional[str] = None, timeout: int = 60, max_retries: int = 3):
        self.api_key = api_key
        self.model_name = model_name
        self.proxy = proxy
        self.timeout = timeout
        self.max_retries = max_retries

    @retry_decorator(max_retries=3)
    async def generate(self, prompt: str) -> Tuple[Optional[str], Union[float, str]]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        start_time = time.time()

        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "response_format": "url"
        }

        conn = aiohttp.TCPConnector(ssl=False)
        timeout = aiohttp.ClientTimeout(total=self.timeout)
        
        headers = {
            "Authorization": f"Bearer {self.api_key}", 
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36", 
            "Content-Type": "application/json"
        }

        async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:
            async with session.post(
                "https://api.kshteam.top/v1/images/generate", 
                headers=headers, 
                json=payload, 
                proxy=self.proxy
            ) as response:
                generation_time = round(time.time() - start_time, 2)
                
                if response.status == 200:
                    data = await response.json()
                    image_url = data.get("data", [{}])[0].get("url", None)

                    if image_url:
                        logger.info(f"Image generated successfully in {generation_time}s")
                        return image_url, generation_time
                    else:
                        error_msg = "–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
                        logger.error(error_msg)
                        return None, error_msg
                else:
                    error_msg = f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {response.status}"
                    logger.error(f"Server error: {response.status} - {await response.text()}")
                    return None, error_msg


@loader.tds
class SunshineGPTEnhanced(loader.Module):
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è –æ–±—â–µ–Ω–∏—è —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ AI –º–æ–¥–µ–ª—è–º–∏:
    
    ‚Ä¢ Gemini (Google AI)
    ‚Ä¢ GPT-4o (OpenAI)
    ‚Ä¢ DeepSeek AI
    
    –¢–∞–∫–∂–µ –≤–∫–ª—é—á–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏:
    
    ‚Ä¢ Flux, Flux Pro, DALL-E 3, MidJourney –∏ –¥—Ä—É–≥–∏–µ
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞, —Ä–∞–±–æ—Ç—É —Å –º–µ–¥–∏–∞—Ñ–∞–π–ª–∞–º–∏ –∏ –º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ.
    """

    strings = {
        "name": "SunshineGPTEnhanced",
        
        # –û–±—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        "no_api_key": "<emoji document_id=5274099962655816924>‚ùóÔ∏è</emoji> <b>API –∫–ª—é—á –Ω–µ —É–∫–∞–∑–∞–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥—É–ª—è.</b>",
        "no_prompt": "<emoji document_id=5274099962655816924>‚ùóÔ∏è</emoji> <b>–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –æ—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –≤–∏–¥–µ–æ, GIF, —Å—Ç–∏–∫–µ—Ä, –≥–æ–ª–æ—Å–æ–≤–æ–µ)</b>",
        "processing": "<emoji document_id=5386367538735104399>‚åõÔ∏è</emoji> <b>{}</b>",
        "request_sent": "<emoji document_id=5325547803936572038>‚ú®</emoji> <b>–ó–∞–ø—Ä–æ—Å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω, –æ–∂–∏–¥–∞–π—Ç–µ –æ—Ç–≤–µ—Ç...</b>",
        "error": "<emoji document_id=5274099962655816924>‚ùóÔ∏è</emoji> <b>–û—à–∏–±–∫–∞:</b> {}",
        "server_error": "<emoji document_id=5274099962655816924>‚ùóÔ∏è</emoji> <b>–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞:</b> {}",
        "empty_response": "<emoji document_id=5274099962655816924>‚ùóÔ∏è</emoji> <b>–û—Ç–≤–µ—Ç –ø—É—Å—Ç–æ–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å.</b>",
        "empty_media": "<emoji document_id=5274099962655816924>‚ùóÔ∏è</emoji> <b>–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:</b> {}",
        "empty_content": "<emoji document_id=5274099962655816924>‚ùóÔ∏è</emoji> <b>–û—à–∏–±–∫–∞: –ó–∞–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–µ–∫—Å—Ç –∏–ª–∏ –º–µ–¥–∏–∞.</b>",
        "describe_this": "<emoji document_id=5386367538735104399>‚åõÔ∏è</emoji> <b>–û–ø–∏—à–∏ —ç—Ç–æ...</b>",
        
        # –°–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        "generating_image": "<emoji document_id=5386367538735104399>‚åõÔ∏è</emoji> <b>–°–µ—Ä–≤–µ—Ä –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...</b>",
        "no_image_prompt": "<emoji document_id=5274099962655816924>‚ùóÔ∏è</emoji> <b>–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.</b>",
        "image_caption": "<blockquote><emoji document_id=5465143921912846619>üí≠</emoji> <b>–ü—Ä–æ–º—Ç:</b> <code>{prompt}</code></blockquote>\n"
                         "<blockquote><emoji document_id=5877260593903177342>‚öôÔ∏è</emoji> <b>–ú–æ–¥–µ–ª—å:</b> <code>{model}</code></blockquote>\n"
                         "<blockquote><emoji document_id=5199457120428249992>üïò</emoji> <b>–í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:</b> {time} —Å–µ–∫.</blockquote>",
        
        # –°–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏—Å—Ç–æ—Ä–∏–∏
        "collecting_history": "<emoji document_id=5386367538735104399>‚åõÔ∏è</emoji> <b>–°–æ–±–∏—Ä–∞—é –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è {}...</b>",
        "collecting_chat": "<emoji document_id=5386367538735104399>‚åõÔ∏è</emoji> <b>–°–æ–±–∏—Ä–∞—é –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞...</b>",
        "user_analysis_title": "<emoji document_id=5873121512445187130>‚ùì</emoji> <b>–ß—Ç–æ —Å–µ–≥–æ–¥–Ω—è –æ–±—Å—É–∂–¥–∞–ª {}?</b>",
        "chat_analysis_title": "<emoji document_id=5873121512445187130>‚ùì</emoji> <b>–ß—Ç–æ —Å–µ–≥–æ–¥–Ω—è –æ–±—Å—É–∂–¥–∞–ª–∏ —É—á–∞—Å—Ç–Ω–∏–∫–∏ —á–∞—Ç–∞?</b>",
        
        # –°–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π AI
        "gemini_response": "<emoji document_id=5325547803936572038>‚ú®</emoji> <b>–û—Ç–≤–µ—Ç –æ—Ç Gemini:</b> {} {}",
        "gpt_response": "<emoji document_id=5325547803936572038>‚ú®</emoji> <b>–û—Ç–≤–µ—Ç –æ—Ç GPT:</b> {} {}",
        "deepseek_response": "<emoji document_id=5325547803936572038>‚ú®</emoji> <b>–û—Ç–≤–µ—Ç –æ—Ç DeepSeek:</b> {} {}",
        
        # –í–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã
        "question": "<emoji document_id=5443038326535759644>üí¨</emoji> <b>–í–æ–ø—Ä–æ—Å:</b> {}",
        
        # –û—à–∏–±–∫–∏ API –∫–ª—é—á–µ–π
        "no_gemini_key": "<emoji document_id=5274099962655816924>‚ùóÔ∏è</emoji> <b>API –∫–ª—é—á –¥–ª—è Gemini –Ω–µ —É–∫–∞–∑–∞–Ω. –ü–æ–ª—É—á–∏—Ç–µ –µ–≥–æ –Ω–∞ aistudio.google.com/apikey</b>",
        "no_openai_key": "<emoji document_id=5274099962655816924>‚ùóÔ∏è</emoji> <b>API –∫–ª—é—á –¥–ª—è OpenAI –Ω–µ —É–∫–∞–∑–∞–Ω. –ü–æ–ª—É—á–∏—Ç–µ –µ–≥–æ –Ω–∞ platform.openai.com</b>",
        "no_deepseek_key": "<emoji document_id=5274099962655816924>‚ùóÔ∏è</emoji> <b>API –∫–ª—é—á –¥–ª—è DeepSeek –Ω–µ —É–∫–∞–∑–∞–Ω. –ü–æ–ª—É—á–∏—Ç–µ –µ–≥–æ –Ω–∞ platform.deepseek.com</b>",
    }

    def __init__(self):
        self.config = loader.ModuleConfig(
            # Gemini –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
            loader.ConfigValue(
                "gemini_api_key", 
                "", 
                "API –∫–ª—é—á –¥–ª—è Gemini AI (aistudio.google.com/apikey)", 
                validator=loader.validators.Hidden(loader.validators.String())
            ),
            loader.ConfigValue(
                "gemini_model_name", 
                "gemini-1.5-flash", 
                "–ú–æ–¥–µ–ª—å –¥–ª—è Gemini AI. –ü—Ä–∏–º–µ—Ä—ã: gemini-1.5-flash, gemini-1.5-pro, gemini-2.0-flash-exp", 
                validator=loader.validators.String()
            ),
            loader.ConfigValue(
                "gemini_system_instruction", 
                "", 
                "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è Gemini AI", 
                validator=loader.validators.String()
            ),
            
            # OpenAI –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
            loader.ConfigValue(
                "openai_api_key", 
                "", 
                "API –∫–ª—é—á –¥–ª—è OpenAI (platform.openai.com)", 
                validator=loader.validators.Hidden(loader.validators.String())
            ),
            loader.ConfigValue(
                "openai_model_name", 
                "gpt-4o", 
                "–ú–æ–¥–µ–ª—å –¥–ª—è OpenAI. –ü—Ä–∏–º–µ—Ä—ã: gpt-4o, gpt-4-turbo, gpt-3.5-turbo", 
                validator=loader.validators.String()
            ),
            loader.ConfigValue(
                "openai_system_instruction", 
                "", 
                "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è OpenAI", 
                validator=loader.validators.String()
            ),
            
            # DeepSeek –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
            loader.ConfigValue(
                "deepseek_api_key", 
                "", 
                "API –∫–ª—é—á –¥–ª—è DeepSeek (platform.deepseek.com)", 
                validator=loader.validators.Hidden(loader.validators.String())
            ),
            loader.ConfigValue(
                "deepseek_model_name", 
                "deepseek-chat", 
                "–ú–æ–¥–µ–ª—å –¥–ª—è DeepSeek. –ü—Ä–∏–º–µ—Ä—ã: deepseek-chat, deepseek-coder", 
                validator=loader.validators.String()
            ),
            loader.ConfigValue(
                "deepseek_system_instruction", 
                "", 
                "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è DeepSeek", 
                validator=loader.validators.String()
            ),
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            loader.ConfigValue(
                "api_key_image", 
                "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c", 
                "–ö–ª—é—á –¥–ª—è API –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", 
                validator=loader.validators.Hidden(loader.validators.String())
            ),
            loader.ConfigValue(
                "default_image_model", 
                "flux", 
                "–ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ü—Ä–∏–º–µ—Ä—ã: flux, flux-pro, flux-dev, flux-schnell, sdxl-turbo, dall-e-3, midjourney", 
                validator=loader.validators.String()
            ),
            
            # –û–±—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            loader.ConfigValue(
                "proxy", 
                "", 
                "–ü—Ä–æ–∫—Å–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ http://<user>:<pass>@<proxy>:<port>, –∏–ª–∏ http://<proxy>:<port>", 
                validator=loader.validators.String()
            ),
            loader.ConfigValue(
                "max_retries", 
                3, 
                "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞", 
                validator=loader.validators.Integer(minimum=1, maximum=5)
            ),
            loader.ConfigValue(
                "timeout", 
                60, 
                "–¢–∞–π–º–∞—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API", 
                validator=loader.validators.Integer(minimum=10, maximum=300)
            ),
            loader.ConfigValue(
                "history_limit", 
                400, 
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏—Å—Ç–æ—Ä–∏–∏", 
                validator=loader.validators.Integer(minimum=50, maximum=1000)
            ),
            loader.ConfigValue(
                "default_ai", 
                "gemini", 
                "AI –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –∫–æ–º–∞–Ω–¥—ã .gpt (gemini, openai, deepseek)", 
                validator=loader.validators.String()
            ),
        )
        
        # –°–ø–∏—Å–æ–∫ —ç–º–æ–¥–∑–∏ –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –æ—Ç–≤–µ—Ç–æ–≤
        self.emojis = [
            "<emoji document_id=5440588507254896965>ü§®</emoji>",
            "<emoji document_id=5443135817998416433>üòï</emoji>",
            "<emoji document_id=5442828624757536533>üòÇ</emoji>",
            "<emoji document_id=5443072677684197457>üòò</emoji>",
            "<emoji document_id=5440854425860061667>üëπ</emoji>",
            "<emoji document_id=5443073472253148107>ü§ì</emoji>",
            "<emoji document_id=5440693467665677594>üö¨</emoji>",
            "<emoji document_id=5440883077586893345>‚òïÔ∏è</emoji>",
            "<emoji document_id=5442843472459481786>ü•≥</emoji>",
            "<emoji document_id=5442927761192665683>ü§≤</emoji>",
            "<emoji document_id=5440814207786303456>üòé</emoji>",
            "<emoji document_id=5442924243614447997>üò°</emoji>",
            "<emoji document_id=5440804385196096498>üëã</emoji>",
            "<emoji document_id=5442795081062956585>‚úã</emoji>",
            "<emoji document_id=5442874134231008257>üëç</emoji>",
            "<emoji document_id=5442639916779454280>üñê</emoji>",
            "<emoji document_id=5442634539480400651>üò∂</emoji>",
            "<emoji document_id=5443010220269782390>üòå</emoji>",
            "<emoji document_id=5440581390494090067>üò≤</emoji>",
            "<emoji document_id=5442674890698145284>üòß</emoji>",
            "<emoji document_id=5443037587801389289>üì≤</emoji>",
            "<emoji document_id=5442864698187856287>üëú</emoji>",
            "<emoji document_id=5442936205098369573>üòê</emoji>",
            "<emoji document_id=5443129680490152331>üëã</emoji>",
            "<emoji document_id=5442868116981824547>üîî</emoji>",
            "<emoji document_id=5440388529282629473>ü´•</emoji>",
            "<emoji document_id=5442876913074847850>üßÆ</emoji>",
            "<emoji document_id=5442644336300802689>üö¨</emoji>",
            "<emoji document_id=5442714550426157926>ü¶¥</emoji>",
            "<emoji document_id=5442869822083841917>üò¥</emoji>",
            "<emoji document_id=5442895299829843652>üò≥</emoji>",
            "<emoji document_id=5443106182724076636>üç´</emoji>",
            "<emoji document_id=5443135796523579899>üíÉ</emoji>",
            "<emoji document_id=5442741651669795615>üò±</emoji>",
            "<emoji document_id=5442613657349405621>üññ</emoji>",
            "<emoji document_id=5442672781869204635>üéâ</emoji>",
            "<emoji document_id=5440474033491560675>‚ò∫Ô∏è</emoji>",
            "<emoji document_id=5442979910685573674>üëç</emoji>",
            "<emoji document_id=5442873906597741574>üó£</emoji>",
            "<emoji document_id=5440412353466222950>üò∂‚Äçüå´Ô∏è</emoji>",
            "<emoji document_id=5442938782078746258>üòÉ</emoji>",
            "<emoji document_id=5443087564040847705>üò†</emoji>",
            "<emoji document_id=5440702594471182364>üêΩ</emoji>",
            "<emoji document_id=5442641505917352670>üí¢</emoji>",
            "<emoji document_id=5444907646626838669>ü•∞</emoji>",
            "<emoji document_id=5445374977723349942>üòí</emoji>",
            "<emoji document_id=5442881062013254513>üòä</emoji>",
            "<emoji document_id=5445375935501055831>üòê</emoji>",
            "<emoji document_id=5445360628237614380>üåÖ</emoji>",
            "<emoji document_id=5445079806095933151>üò¶</emoji>",
            "<emoji document_id=5444946571915444568>ü§∑‚Äç‚ôÇÔ∏è</emoji>",
            "<emoji document_id=5445017237012363750>ü•≥</emoji>",
            "<emoji document_id=5442859243579393479>ü§¶‚Äç‚ôÄÔ∏è</emoji>",
            "<emoji document_id=5444950785278362209>üòé</emoji>",
            "<emoji document_id=5445398230676291110>ü§£</emoji>",
            "<emoji document_id=5445333290770775391>üëÄ</emoji>",
            "<emoji document_id=5445255122365988661>üòï</emoji>",
            "<emoji document_id=5445159739732279716>ü´•</emoji>"
        ]
        
        # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        self._models = {}

    async def client_ready(self, client, db):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞"""
        self.client = client
        self.db = db
        
        if self.config["proxy"]:
            os.environ["HTTP_PROXY"] = self.config["proxy"]
            os.environ["HTTPS_PROXY"] = self.config["proxy"]
            logger.info(f"Proxy set to {self.config['proxy']}")

    def _get_mime_type(self, message) -> Optional[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç MIME-—Ç–∏–ø –º–µ–¥–∏–∞ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏"""
        if not message:
            return None

        try:
            if getattr(message, "video", None) or getattr(message, "video_note", None):
                return "video/mp4"
            elif getattr(message, "animation", None) or (getattr(message, "sticker", None) and getattr(message.sticker, "is_video", False)):
                return "video/mp4"
            elif getattr(message, "voice", None) or getattr(message, "audio", None):
                return "audio/wav"
            elif getattr(message, "photo", None):
                return "image/png"
            elif getattr(message, "sticker", None):
                return "image/webp"
            elif getattr(message, "document", None):
                # –ü–æ–ø—ã—Ç–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                file_name = getattr(message.document, "file_name", "").lower()
                if file_name.endswith((".jpg", ".jpeg")):
                    return "image/jpeg"
                elif file_name.endswith(".png"):
                    return "image/png"
                elif file_name.endswith(".gif"):
                    return "image/gif"
                elif file_name.endswith((".mp4", ".avi", ".mov")):
                    return "video/mp4"
                elif file_name.endswith((".mp3", ".wav", ".ogg")):
                    return "audio/mpeg"
                
        except AttributeError as e:
            logger.error(f"Error getting mime type: {e}")
            return None

        return None

    async def _get_random_emoji(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π —ç–º–æ–¥–∑–∏ –∏–∑ —Å–ø–∏—Å–∫–∞"""
        return random.choice(self.emojis)
        
    def _get_model(self, model_type: str):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å AI –ø–æ —Ç–∏–ø—É"""
        if model_type in self._models:
            return self._models[model_type]
            
        if model_type == "gemini":
            if not self.config["gemini_api_key"]:
                raise ValueError("API –∫–ª—é—á –¥–ª—è Gemini –Ω–µ —É–∫–∞–∑–∞–Ω")
                
            model = GeminiModel(
                api_key=self.config["gemini_api_key"],
                model_name=self.config["gemini_model_name"],
                system_instruction=self.config["gemini_system_instruction"],
                proxy=self.config["proxy"],
                timeout=self.config["timeout"]
            )
            
        elif model_type == "openai":
            if not self.config["openai_api_key"]:
                raise ValueError("API –∫–ª—é—á –¥–ª—è OpenAI –Ω–µ —É–∫–∞–∑–∞–Ω")
                
            model = ChatGPTModel(
                api_key=self.config["openai_api_key"],
                model_name=self.config["openai_model_name"],
                proxy=self.config["proxy"],
                timeout=self.config["timeout"]
            )
            
        elif model_type == "deepseek":
            if not self.config["deepseek_api_key"]:
                raise ValueError("API –∫–ª—é—á –¥–ª—è DeepSeek –Ω–µ —É–∫–∞–∑–∞–Ω")
                
            model = DeepSeekModel(
                api_key=self.config["deepseek_api_key"],
                model_name=self.config["deepseek_model_name"],
                proxy=self.config["proxy"],
                timeout=self.config["timeout"]
            )
            
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏: {model_type}")
            
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        self._models[model_type] = model
        return model

    async def _process_ai_query(self, model_type: str, prompt: str, media_path: Optional[str] = None, mime_type: Optional[str] = None, system_prompt: Optional[str] = None) -> str:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ AI —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –º–µ–¥–∏–∞ —Ñ–∞–π–ª–æ–º"""
        try:
            model = self._get_model(model_type)
            
            if media_path and mime_type and mime_type.startswith("image"):
                with open(media_path, "rb") as f:
                    image_data = f.read()
                    
                result = await model.generate_with_image(prompt, image_data, mime_type, system_prompt)
            else:
                result = await model.generate_text(prompt, system_prompt)
                
            return result.strip() if result else self.strings["empty_response"]
            
        except Exception as e:
            logger.exception(f"Error in AI query processing: {e}")
            raise

    async def generate_image(self, prompt: str) -> Tuple[Optional[str], Union[float, str]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å API"""
        generator = ImageGenerator(
            api_key=self.config["api_key_image"],
            model_name=self.config["default_image_model"],
            proxy=self.config["proxy"],
            timeout=self.config["timeout"],
            max_retries=self.config["max_retries"]
        )
        
        return await generator.generate(prompt)

    async def _process_ai_command(self, message, model_type: str, response_template: str):
        """–û–±—â–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–º–∞–Ω–¥ AI –º–æ–¥–µ–ª–µ–π"""
        if model_type == "gemini" and not self.config["gemini_api_key"]:
            await utils.answer(message, self.strings["no_gemini_key"])
            return
        elif model_type == "openai" and not self.config["openai_api_key"]:
            await utils.answer(message, self.strings["no_openai_key"])
            return
        elif model_type == "deepseek" and not self.config["deepseek_api_key"]:
            await utils.answer(message, self.strings["no_deepseek_key"])
            return

        prompt = utils.get_args_raw(message)
        media_path = None
        img = None
        show_question = True
        mime_type = None

        try:
            if message.is_reply:
                reply = await message.get_reply_message()
                mime_type = self._get_mime_type(reply)

                if mime_type:
                    media_path = await reply.download_media()
                    if not prompt:
                        prompt = "–û–ø–∏—à–∏ —ç—Ç–æ"
                        await utils.answer(message, self.strings["describe_this"])
                        show_question = False
                else:
                    prompt = prompt or reply.text

            if media_path and mime_type and mime_type.startswith("image"):
                try:
                    img = Image.open(media_path)
                except Exception as e:
                    await utils.answer(message, self.strings["empty_media"].format(e))
                    if media_path and os.path.exists(media_path):
                        with suppress(Exception):
                            os.remove(media_path)
                    return

            if not prompt and not img and not media_path:
                await utils.answer(message, self.strings["no_prompt"])
                return

            await utils.answer(message, self.strings["request_sent"])

            # –í—ã–±–∏—Ä–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–æ–¥–µ–ª–∏
            if model_type == "gemini":
                system_prompt = self.config["gemini_system_instruction"]
            elif model_type == "openai":
                system_prompt = self.config["openai_system_instruction"]
            elif model_type == "deepseek":
                system_prompt = self.config["deepseek_system_instruction"]
            else:
                system_prompt = None

            reply_text = await self._process_ai_query(model_type, prompt, media_path, mime_type, system_prompt)
            random_emoji = await self._get_random_emoji()

            if show_question and prompt != "–û–ø–∏—à–∏ —ç—Ç–æ":
                response = f"{self.strings['question'].format(prompt)}\n\n{response_template.format(reply_text, random_emoji)}"
            else:
                response = f"\n{response_template.format(reply_text, random_emoji)}"
            
            await utils.answer(message, response)
            
        except ValueError as e:
            await utils.answer(message, self.strings["error"].format(str(e)))
        except Exception as e:
            logger.exception(f"Error in AI command: {e}")
            await utils.answer(message, self.strings["error"].format(str(e)))
        finally:
            if media_path and os.path.exists(media_path):
                with suppress(Exception):
                    os.remove(media_path)

    @loader.command(alias="gpt")
    async def ai(self, message):
        """‚Äî –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ AI (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫)"""
        model_type = self.config["default_ai"]
        
        if model_type == "gemini":
            response_template = self.strings["gemini_response"]
        elif model_type == "openai":
            response_template = self.strings["gpt_response"]
        elif model_type == "deepseek":
            response_template = self.strings["deepseek_response"]
        else:
            response_template = self.strings["gemini_response"]
            model_type = "gemini"
            
        await self._process_ai_command(message, model_type, response_template)

    @loader.command()
    async def gemini(self, message):
        """‚Äî –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ Google Gemini"""
        await self._process_ai_command(message, "gemini", self.strings["gemini_response"])

    @loader.command()
    async def cgpt(self, message):
        """‚Äî –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ ChatGPT (OpenAI)"""
        await self._process_ai_command(message, "openai", self.strings["gpt_response"])

    @loader.command()
    async def dseek(self, message):
        """‚Äî –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ DeepSeek AI"""
        await self._process_ai_command(message, "deepseek", self.strings["deepseek_response"])

    @loader.command()
    async def gimg(self, message):
        """‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        prompt = utils.get_args_raw(message)
        if not prompt:
            await utils.answer(message, self.strings["no_image_prompt"])
            return

        await utils.answer(message, self.strings["generating_image"])

        image_url, generation_time = await self.generate_image(prompt)

        if image_url:
            timeout = aiohttp.ClientTimeout(total=30)
            conn = aiohttp.TCPConnector(ssl=False)
            
            try:
                async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:
                    async with session.get(image_url) as img_response:
                        if img_response.status != 200:
                            await utils.answer(message, self.strings["error"].format(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–∫–æ–¥: {img_response.status})"))
                            return
                            
                        img_content = io.BytesIO(await img_response.read())
                        img_content.name = f"generated_image_{int(time.time())}.png"

                        caption = self.strings["image_caption"].format(
                            prompt=prompt,
                            model=self.config['default_image_model'],
                            time=generation_time
                        )

                        await utils.answer_file(message, img_content, caption=caption)

            except Exception as e:
                logger.exception(f"Error downloading generated image: {e}")
                await utils.answer(message, self.strings["error"].format(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}"))
        else:
            await utils.answer(message, self.strings["error"].format(generation_time))

    @loader.command()
    async def ghist(self, message):
        """- –∞–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π —á–∞—Ç–∞ –∏–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å –æ—Ç–≤–µ—Ç–æ–º –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ)"""
        if self.config["default_ai"] == "gemini" and not self.config["gemini_api_key"]:
            await utils.answer(message, self.strings["no_gemini_key"])
            return
        elif self.config["default_ai"] == "openai" and not self.config["openai_api_key"]:
            await utils.answer(message, self.strings["no_openai_key"])
            return
        elif self.config["default_ai"] == "deepseek" and not self.config["deepseek_api_key"]:
            await utils.answer(message, self.strings["no_deepseek_key"])
            return

        user = None
        user_name = ""
        history_limit = self.config["history_limit"]
        
        if message.is_reply:
            reply = await message.get_reply_message()
            user = reply.sender_id if reply.sender else None
            user_name = reply.sender.first_name if reply.sender else "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"
            if user:
                await utils.answer(message, self.strings["collecting_history"].format(user_name))
            else:
                await utils.answer(message, self.strings["collecting_chat"])
        else:
            await utils.answer(message, self.strings["collecting_chat"])

        try:
            chat_id = message.chat_id
            all_messages = []
            
            total_collected = 0
            async for msg in self.client.iter_messages(chat_id, limit=history_limit):
                if msg and msg.sender and not getattr(msg.sender, "bot", False) and not msg.action:
                    sender_id = msg.sender_id if hasattr(msg, "sender_id") else 0
                    sender_name = msg.sender.first_name if hasattr(msg.sender, "first_name") else "Unknown"
                    
                    if user and sender_id != user:
                        continue
                        
                    msg_text = msg.text if msg.text else ""
                    if not msg_text and msg.media:
                        msg_text = "[–º–µ–¥–∏–∞]"
                    
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                    if not msg_text:
                        continue
                    
                    message_data = {
                        "sender": sender_name,
                        "time": msg.date.strftime("%H:%M:%S"),
                        "text": msg_text
                    }
                    
                    all_messages.append(message_data)
                    total_collected += 1
                    
                if total_collected >= history_limit:
                    break
            
            if not all_messages:
                await utils.answer(message, self.strings["error"].format("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"))
                return
                
            all_messages.sort(key=lambda x: x["time"])
            
            context = "–ù–∏–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —á–∞—Ç–∞. "
            if user:
                context += f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_name} –∏ —Å–æ—Å—Ç–∞–≤—å –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É –æ —á–µ–º –æ–Ω –ø–∏—Å–∞–ª —Å–µ–≥–æ–¥–Ω—è, "
                context += "–µ–≥–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞—Ö, –≤–æ–ø—Ä–æ—Å–∞—Ö, –æ–±—â–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏. –í—ã–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –æ–±—Å—É–∂–¥–µ–Ω–∏—è. –í –∫–æ–Ω—Ü–µ –Ω–∞–ø–∏—à–∏ —à—É—Ç–∫—É –ø—Ä–æ —Ç–æ —á—Ç–æ —Ç—ã –ø—Ä–æ—á–∏—Ç–∞–ª –∏ –∑–∞–ø–∏—à–∏ –∫–∞–∫ –®—É—Ç–∫–∞ –æ—Ç –ò–ò:"
                title = self.strings["user_analysis_title"].format(user_name)
            else:
                context += "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ —Å–æ—Å—Ç–∞–≤—å –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É –æ —Ç–æ–º, —á—Ç–æ –æ–±—Å—É–∂–¥–∞–ª–æ—Å—å –≤ —á–∞—Ç–µ —Å–µ–≥–æ–¥–Ω—è. "
                context += "–í—ã–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –æ–±—Å—É–∂–¥–µ–Ω–∏—è, –∞–∫—Ç–∏–≤–Ω—ã—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤, –æ–±—â–µ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –±–µ—Å–µ–¥—ã. –í –∫–æ–Ω—Ü–µ –Ω–∞–ø–∏—à–∏ —à—É—Ç–∫—É –ø—Ä–æ —Ç–æ —á—Ç–æ —Ç—ã –ø—Ä–æ—á–∏—Ç–∞–ª –∏ –∑–∞–ø–∏—à–∏ –∫–∞–∫ –®—É—Ç–∫–∞ –æ—Ç –ò–ò:"
                title = self.strings["chat_analysis_title"]
                
            history_text = "\n".join([f"[{msg['time']}] {msg['sender']}: {msg['text']}" for msg in all_messages])
            
            prompt = f"{context}\n\n–ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π:\n{history_text}"
            
            processing_msg = await utils.answer(
                message, 
                self.strings["processing"].format("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–æ–æ–±—â–µ–Ω–∏—è...")
            )
            
            # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏—Å—Ç–æ—Ä–∏–∏
            model_type = self.config["default_ai"]
            analysis = await self._process_ai_query(model_type, prompt)
            
            random_emoji = await self._get_random_emoji()
            result = f"{title}\n\n{analysis} {random_emoji}"
            
            await utils.answer(processing_msg, result)
            
        except Exception as e:
            logger.exception(f"Error in ghist: {e}")
            await utils.answer(message, self.strings["error"].format(e))

    @loader.command()
    async def amodels(self, message):
        """‚Äî –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ò–ò"""
        available_models = {
            "Gemini": [
                "gemini-1.5-flash", 
                "gemini-1.5-pro", 
                "gemini-2.0-flash-exp", 
                "gemini-2.0-flash-thinking-exp-1219"
            ],
            "OpenAI": [
                "gpt-4o", 
                "gpt-4-turbo", 
                "gpt-4-vision", 
                "gpt-3.5-turbo"
            ],
            "DeepSeek": [
                "deepseek-chat", 
                "deepseek-coder", 
                "deepseek-lite"
            ],
            "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π": [
                "flux", 
                "flux-pro", 
                "flux-dev", 
                "flux-schnell", 
                "dall-e-3", 
                "midjourney", 
                "sdxl-turbo"
            ]
        }
        
        msg = "<emoji document_id=5877260593903177342>‚öôÔ∏è</emoji> <b>–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ò–ò:</b>\n\n"
        
        for category, models in available_models.items():
            msg += f"<emoji document_id=5325547803936572038>‚ú®</emoji> <b>{category}:</b>\n"
            for model in models:
                msg += f"  ‚Ä¢ <code>{model}</code>\n"
            msg += "\n"
        
        msg += "<b>–ö–∞–∫ –∏–∑–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å:</b>\n"
        msg += "‚Ä¢ –î–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ Gemini –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ <code>.config SunshineGPTEnhanced gemini_model_name –º–æ–¥–µ–ª—å</code>\n"
        msg += "‚Ä¢ –î–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ OpenAI –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ <code>.config SunshineGPTEnhanced openai_model_name –º–æ–¥–µ–ª—å</code>\n"
        msg += "‚Ä¢ –î–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ DeepSeek –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ <code>.config SunshineGPTEnhanced deepseek_model_name –º–æ–¥–µ–ª—å</code>\n"
        msg += "‚Ä¢ –î–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ <code>.config SunshineGPTEnhanced default_image_model –º–æ–¥–µ–ª—å</code>\n"
        
        await utils.answer(message, msg)

    @loader.command()
    async def ahelp(self, message):
        """‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –ø–æ–º–æ—â—å –ø–æ –º–æ–¥—É–ª—é"""
        reply = "<emoji document_id=5325547803936572038>‚ú®</emoji> <b>SunshineGPT Enhanced</b>\n\n"
        reply += "<b>–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:</b>\n"
        reply += "‚Ä¢ <code>.ai</code> –∏–ª–∏ <code>.gpt</code> - –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ AI –º–æ–¥–µ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n"
        reply += "‚Ä¢ <code>.gemini</code> - –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ Google Gemini\n"
        reply += "‚Ä¢ <code>.cgpt</code> - –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ ChatGPT (OpenAI)\n"
        reply += "‚Ä¢ <code>.dseek</code> - –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ DeepSeek AI\n"
        reply += "‚Ä¢ <code>.gimg</code> - —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n"
        reply += "‚Ä¢ <code>.ghist</code> - –∞–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞ (–º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å –æ—Ç–≤–µ—Ç–æ–º –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)\n"
        reply += "‚Ä¢ <code>.amodels</code> - –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π AI\n\n"
        
        reply += "<b>–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥—É–ª—è:</b>\n"
        reply += "‚Ä¢ API –∫–ª—é—á–∏ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –º–æ–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —á–µ—Ä–µ–∑ <code>.config SunshineGPTEnhanced</code>\n"
        reply += "‚Ä¢ –ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: <code>.config SunshineGPTEnhanced default_ai –º–æ–¥–µ–ª—å</code> (gemini, openai, deepseek)\n"
        reply += "‚Ä¢ –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: <code>.config SunshineGPTEnhanced {–º–æ–¥–µ–ª—å}_system_instruction —Ç–µ–∫—Å—Ç</code>\n\n"
        
        reply += "<b>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å –º–µ–¥–∏–∞:</b>\n"
        reply += "‚Ä¢ –û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –≤–∏–¥–µ–æ, GIF, —Å—Ç–∏–∫–µ—Ä –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–æ–º–∞–Ω–¥–æ–π\n"
        reply += "‚Ä¢ –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω –∑–∞–ø—Ä–æ—Å, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∑–∞–ø—Ä–æ—Å ¬´–û–ø–∏—à–∏ —ç—Ç–æ¬ª\n\n"
        
        reply += "<b>–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:</b>\n"
        reply += "‚Ä¢ <code>.gimg –≤–∞—à –ø—Ä–æ–º–ø—Ç</code> - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é\n"
        reply += "‚Ä¢ –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: <code>.config SunshineGPTEnhanced default_image_model –º–æ–¥–µ–ª—å</code>\n\n"
        
        reply += "<b>–í–µ—Ä—Å–∏—è:</b> 1.4.8.8"
        
        await utils.answer(message, reply)
